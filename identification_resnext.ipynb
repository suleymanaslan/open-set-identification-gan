{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models, datasets\n",
    "\n",
    "import utils\n",
    "\n",
    "\n",
    "plt.style.use(\"dark_background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_timestamp = str(int(time.time()))\n",
    "model_dir = f'trained_models/model_identification_resnext_{training_timestamp}/'\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    \n",
    "shutil.copy2('./identification_resnext.ipynb', model_dir)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "data_transforms = {'aligned_train': transforms.Compose([transforms.Resize(224),\n",
    "                                                        transforms.RandomHorizontalFlip(),\n",
    "                                                        transforms.ToTensor(),\n",
    "                                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "                   'aligned_val': transforms.Compose([transforms.Resize(224),\n",
    "                                                      transforms.ToTensor(),\n",
    "                                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "                  }\n",
    "\n",
    "data_dir = 'data/'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['aligned_train', 'aligned_val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, drop_last=True) for x in ['aligned_train', 'aligned_val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['aligned_train', 'aligned_val']}\n",
    "class_names = image_datasets['aligned_train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "real_batch, real_classes = next(iter(dataloaders['aligned_train']))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow((np.transpose(real_batch[0].numpy(), (1, 2, 0))*np.array([0.229, 0.224, 0.225]))+np.array([0.485, 0.456, 0.406]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnext50_32x4d = models.resnext50_32x4d(pretrained=True)\n",
    "resnext50_32x4d.fc = nn.Linear(resnext50_32x4d.fc.in_features, 46)\n",
    "resnext50_32x4d = resnext50_32x4d.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(resnext50_32x4d.parameters(), lr=0.001)\n",
    "\n",
    "utils.print_and_log(model_dir, resnext50_32x4d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "unknown_id = 45\n",
    "\n",
    "best_model = copy.deepcopy(resnext50_32x4d.state_dict())\n",
    "best_acc = 0.0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "utils.print_and_log(model_dir, f\"{datetime.now()} Starting Training\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for phase in ['aligned_train', 'aligned_val']:\n",
    "        if phase == 'aligned_train':\n",
    "            utils.print_and_log(model_dir, f\"{datetime.now()} Epoch {epoch+1}/{num_epochs} Training\")\n",
    "            resnext50_32x4d.train()\n",
    "        else:\n",
    "            utils.print_and_log(model_dir, f\"{datetime.now()} Epoch {epoch+1}/{num_epochs} Validation\")\n",
    "            resnext50_32x4d.eval()\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        epoch_acc = 0.0\n",
    "        epoch_iter = 0\n",
    "        \n",
    "        epoch_unknown_correct = 0\n",
    "        epoch_unknown_total = 0\n",
    "        epoch_known_correct = 0\n",
    "        epoch_known_total = 0\n",
    "        \n",
    "        for batch_index, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'aligned_train'):\n",
    "                outputs = resnext50_32x4d(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                unknown_correct = torch.sum((preds == unknown_id) & (labels.data == unknown_id)).item()\n",
    "                unknown_total = torch.sum(labels.data == unknown_id).item()\n",
    "                known_correct = torch.sum(preds == labels.data).item() - unknown_correct\n",
    "                known_total = inputs.size(0) - unknown_total\n",
    "\n",
    "                if phase == 'aligned_train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    train_losses.append(loss.item())\n",
    "                    if batch_index % 20 == 0:\n",
    "                        utils.print_and_log(model_dir, f\"{datetime.now()} [{epoch+1:02d}/{num_epochs}][{batch_index:04d}/{len(dataloaders[phase])}] \"\n",
    "                                            f\"Loss:{loss.item():.4f} Acc:{torch.sum(preds == labels.data).item()/inputs.size(0):.4f} \"\n",
    "                                            f\"Corrects(Known):{known_correct:02d}/{known_total:02d} \"\n",
    "                                            f\"Corrects(Unknown):{unknown_correct:02d}/{unknown_total:02d}\")\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                epoch_acc += torch.sum(preds == labels.data).item()/inputs.size(0)\n",
    "                epoch_iter += 1\n",
    "\n",
    "                epoch_unknown_correct += unknown_correct\n",
    "                epoch_unknown_total += unknown_total\n",
    "                epoch_known_correct += known_correct\n",
    "                epoch_known_total += known_total\n",
    "        \n",
    "        epoch_loss = epoch_loss / epoch_iter\n",
    "        epoch_acc = epoch_acc / epoch_iter\n",
    "        if phase == \"aligned_train\":\n",
    "            utils.print_and_log(model_dir, f\"{datetime.now()} [{epoch+1:02d}/{num_epochs}] Train Loss: {epoch_loss:.4f} Train Acc: {epoch_acc:.4f} \"\n",
    "                                f\"Corrects(Known):{epoch_known_correct:04d}/{epoch_known_total:04d} Corrects(Unknown):{epoch_unknown_correct:04d}/{epoch_unknown_total:04d}\")\n",
    "        \n",
    "        else:\n",
    "            utils.print_and_log(model_dir, f\"{datetime.now()} [{epoch+1:02d}/{num_epochs}] Val Loss: {epoch_loss:.4f} Val Acc: {epoch_acc:.4f} \"\n",
    "                                f\"Corrects(Known):{epoch_known_correct:04d}/{epoch_known_total:04d} Corrects(Unknown):{epoch_unknown_correct:04d}/{epoch_unknown_total:04d}\")\n",
    "            val_losses.append(epoch_loss)\n",
    "            \n",
    "            if epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model = copy.deepcopy(resnext50_32x4d.state_dict())\n",
    "\n",
    "utils.print_and_log(model_dir, f\"{datetime.now()} Best Val Acc:{best_acc:4f}\")\n",
    "resnext50_32x4d.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnext50_32x4d.state_dict(), f\"{model_dir}/model_{best_acc:.4f}.pth\")\n",
    "np.save(f\"{model_dir}/train_losses.npy\" , np.array(train_losses))\n",
    "np.save(f\"{model_dir}/val_losses.npy\" , np.array(val_losses))\n",
    "\n",
    "train_epoch_step = len(train_losses)//len(val_losses)\n",
    "\n",
    "train_plot_steps = np.arange(len(train_losses))+1\n",
    "val_plot_steps = (np.arange(len(val_losses))+1)*train_epoch_step\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Losses\")\n",
    "plt.plot(train_plot_steps, train_losses, label='train_loss', linewidth=3)\n",
    "plt.plot(val_plot_steps, val_losses, label='val_loss', linewidth=3)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"{model_dir}/loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnext50_32x4d.eval()\n",
    "num_images = 3\n",
    "\n",
    "with torch.no_grad():\n",
    "    val_inputs, val_labels = next(iter(dataloaders['aligned_val']))\n",
    "    val_inputs = val_inputs.to(device)\n",
    "    val_labels = val_labels.to(device)\n",
    "    \n",
    "    outputs = resnext50_32x4d(val_inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    for j in range(num_images):\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.title(f\"Actual:{class_names[val_labels[j]]}, Predicted:{class_names[preds[j]]}\")\n",
    "        plt.imshow((np.transpose(val_inputs[j].cpu().numpy(), (1, 2, 0))*np.array([0.229, 0.224, 0.225]))+np.array([0.485, 0.456, 0.406]))\n",
    "        plt.savefig(f\"{model_dir}/sample_predicted_{j}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
